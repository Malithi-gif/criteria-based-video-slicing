# -*- coding: utf-8 -*-
"""Analyse video data .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SFRtonOlJE41p85EqTnobXhJhZd3BcMi

## Name:

W.K.M Mithsara

## Problem:

The data file “video_data.csv” contains the following details of YouTube videos:
- No of likes
- No of dislikes
- No of subscribers
- No of views

It is needed to design machine learning models to predict the no of views given the no of likes, no of dislikes and no of subscribers.

## Tasks:

### 01. [05 marks] Import the required Python libraries to the notebook.
"""

from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
import io
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.optimizers import Adam
from sklearn.metrics import r2_score
from keras.models import Sequential

"""### 02.	[05 marks] Read the given data file (video_data.csv) into a Pandas data frame (name it as ‘df’)."""

uploaded = files.upload()
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

uploaded

df = pd.read_csv(io.StringIO(uploaded['video_data.csv'].decode('utf-8')))

"""### 03.	[05 marks] Display the first five data points of the file using the “head()” function."""

df.head()

"""### 04.	[05 marks] Obtain the descriptive statistics of no of likes, no of dislikes, no of subscribers and no of views."""

df.describe()

"""### 05.	[05 marks] Draw three (03) separate scatter plots that show the no of views against the no of likes, no of dislikes and no of subscribers.

Codes (Plot 1 -  No of views Vs. No of likes)
"""

df.plot(kind='scatter',x='Views',y='Likes') # scatter plot

"""Codes (Plot 2 - No of views Vs. No of dislikes)"""

df.plot(kind='scatter',x='Views',y='Dislikes') # scatter plot

"""Codes (Plot 3 -  No of views Vs. No of subscribers)"""

df.plot(kind='scatter',x='Views',y='Subscribers') # scatter plot

"""### 06.	[05 marks] Split the dataset into two datasets for the training and testing. Use 80% for training and the remaining for the testing."""

dataset = df.values

#print dataset

X = dataset[:,0:3].astype('float32')
y = dataset[:,3]


X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)
print "Size(X_train) = ", X_train.shape
print "Size(X_test) = ", X_test.shape
print "Size(y_train) = ", y_train.shape
print "Size(y_test) = ", y_test.shape

"""### 07.	[05 marks] Scale X data (no of likes, no of dislikes and no of subscribers) of the training dataset to mean 0 and standard deviation 1. Apply the same transformation to X data of the testing dataset."""

min_max_scaler = preprocessing.MinMaxScaler()
X_train_scaled = min_max_scaler.fit_transform(X_train)
X_test_scaled = min_max_scaler.fit_transform(X_test)

#print X_train_scaled
#print X_test_scaled

"""### 08.	[05 marks] Design a linear regression model (name it as “model_reg”) using the training dataset. Use “Keras” Python library to design this model. Print a summary of the model that shows Layer, Output Shape, Number of parameters, etc.

<b><u>Note:</u></b> Add “\_reg” suffix to each variable you define for the regression model as in “model\_reg” here after.
"""

model_reg = Sequential()
INPUT_DIM_REG=3
model_reg.add(Dense(1, input_dim=INPUT_DIM_REG, activation='linear'))
model_reg.summary()

"""### 09.	[05 marks] Compile the model. Use “Adam” optimizer (instead of SGD) with the learning rate 10,000 and loss as mean squared error."""

OPTIMIZER = Adam(lr=10000)
model_reg.compile(optimizer=OPTIMIZER, loss='mean_squared_error', metrics=['accuracy'])

"""### 10.	[05 marks] Fit the model using the training dataset. Use batch size as 32, no of epochs as 1000 and verbose as 1."""

model_history =model_reg.fit(X_train, y_train, batch_size=32, epochs=1000,verbose=1 )

"""### 11.	[03 marks] Plot the loss of the training process against the epochs."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

def plot_history(network_history):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(network_history.history['loss'])
    plt.legend(['Training'])


plot_history(model_history)

"""### 12.	[03 marks] Find the predicted no of views for the training and testing datasets."""

X_train_predictions = model_reg.predict(X_train)
print X_train_predictions

X_test_predictions = model_reg.predict(X_test)
print X_test_predictions

"""### 	13. [05 marks] Draw two (02) scatter plots that show the predicted no of views against the original no of views for the training and testing datasets. Note that if your predicted values are closer to the original values, points of the plot scatter around the line $y=x$.

Codes (Plot 1 - Predicted no of views Vs. Original no of views for the training dataset)
"""

# Plot

plt.scatter(X_train_predictions, y_train, alpha=0.5)
plt.xlabel("predicted")
plt.ylabel("original")
plt.show()

"""Codes (Plot 2 - Predicted no of views Vs. Original no of views for the testing dataset)"""

# Plot

plt.scatter(X_test_predictions, y_test, alpha=0.5)
plt.xlabel("predicted")
plt.ylabel("original")
plt.show()

"""### 	14. [05 marks] Compute the $R^2$ values for these predicted no of views and original no of views for both training and testing datasets. Note that if your model is perfectly fitted, $R^2$ values should be close to 1."""

print "Testing Dataset:"
print r2_score(y_test, X_test_predictions)

print "Training Dataset:"
print r2_score(y_train, X_train_predictions)

"""### 15.	[05 marks] Design a neural network (name it as “model_dnn”) with 4 hidden layers, each layer contains 13 neurons. Use the “relu” activation function in the input and hidden layers. Print a summary of the model that shows Layer, Output Shape, Number of parameters, etc.

<b><u>Note:</u></b> Add “\_dnn” suffix to each variable you define for the deep neural network model as in ‘model\_dnn’ here after.
"""

model_dnn = Sequential()
model_dnn.add(Dense(13, input_dim=3, kernel_initializer='normal', activation='relu'))
model_dnn.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model_dnn.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model_dnn.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model_dnn.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model_dnn.add(Dense(1, kernel_initializer='normal'))
# Compile model
model_dnn.compile(loss='mean_squared_error', optimizer='adam')

model_dnn.summary()

"""### 16.	[05 marks] Compile the model. Use “Adam” optimizer (instead of SGD) with the learning rate 0.003 and loss as mean squared error."""

OPTIMIZER = Adam(lr=0.003)
model_dnn.compile(optimizer=OPTIMIZER, loss='mean_squared_error', metrics=['accuracy'])

"""### 17.	[05 marks] Fit the model using the training dataset. Use batch size as 32, no of epochs as 1000 and verbose as 1."""

model_history_dnn =model_dnn.fit(X_train, y_train, batch_size=32, epochs=1000,verbose=1 )

"""### 18.	[02 marks] Plot the loss of the training process against the epochs."""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

def plot_history(network_history):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(network_history.history['loss'])
    plt.legend(['Training'])


plot_history(model_history_dnn)

"""### 19.	[02 marks] Find the predicted no of views for the training and testing datasets."""

X_train_predictions_dnn = model_dnn.predict(X_train)
print X_train_predictions_dnn

X_test_predictions_dnn = model_dnn.predict(X_test)
print X_test_predictions_dnn

"""### 20. [05 marks] Draw two (02) scatter plots that show the predicted no of views against the original no of views for the training and testing datasets. Note that if your predicted values are closer to the original values, points of the plot scatter around the line $y=x$.

Codes (Plot 1 - Predicted no of views Vs. Original no of views for the training dataset)
"""

# Plot

plt.scatter(X_train_predictions_dnn, y_train, alpha=0.5)
plt.xlabel("predicted")
plt.ylabel("original")
plt.show()

"""Codes (Plot 2 - Predicted no of views Vs. Original no of views for the testing dataset)"""

# Plot

plt.scatter(X_test_predictions_dnn, y_test, alpha=0.5)
plt.xlabel("predicted")
plt.ylabel("original")
plt.show()

"""### 21. [05 marks] Compute the $R^2$ values for these predicted no of views and original no of views for both training and testing datasets. Note that if your model is perfectly fitted, $R^2$ values should be close to 1."""

print "Training Dataset:"
print r2_score(y_train, X_train_predictions_dnn)

print "Testing Dataset:"
print r2_score(y_test, X_test_predictions_dnn)

"""### 22.	[05 marks] Discuss the results obtained from two models and explain which model is more appropriate for the problem.

When we train model using linear regression model,the scatter plot loss of the training process against the epochs shows higher losses than neural network model.

In liner regression model,points in scatter plot that show the predicted no of views against the original no of views for the training and testing datasets not around the line  y=x.So predicted values are not closer to the original values. 

In Neural network model,points in scatter plot that show the predicted no of views against the original no of views for the training and testing datasets,are around the line  y=x.So predicted values are closer to the original values.

In linear regression model, R2 is -1575262.418283122 for testing dataset. But In neural network model R2 is 0.8100379216926125.So linear regression model is more fit than neural network model.So We can say linear regression model is more appropriate for the problem.


**But in case here, In linear regression model we used learning rate as 10000.Large learning rates result in unstable training and tiny rates result in a failure to train.If learning rate in linear regression model is small(0.1) learning rate in neural network model is 0.003 then linear regression model is more appropriate than the neural network model.**

<center><h2>---END---</h2></center>
"""
